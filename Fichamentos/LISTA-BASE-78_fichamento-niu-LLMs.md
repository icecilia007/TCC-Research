# On Evaluating the Efficiency of Source Code Generated by LLMs

Niu, Changan; Zhang, Ting; Li, Chuanyi; Luo, Bin; Ng, Vincent. "On Evaluating the Efficiency of Source Code Generated by LLMs," AI Foundation Models and Software Engineering (FORGE ’24), April 14, 2024, Lisbon, Portugal, pp. 1–5. doi:10.1145/3650105.3652295

## 1. Fichamento de Conteúdo

Este estudo investiga a **eficiência** de código gerado por *large language models* (*LLMs*) além de sua **correção funcional**. Utilizando benchmarks *HumanEval*, *MBPP* e um conjunto complexo de problemas do *LeetCode*, mede-se o *runtime* médio normalizado do código em um simulador *gem5* ou diretamente pela plataforma LeetCode, comparando modelos como GPT-4, GPT-3.5, *Code Llama*, *WizardCoder*, *Phi-2* e *DeepSeek Coder*. Observa-se que eficiência não se correlaciona com tamanho de modelo nem com taxa de acertos, e que estratégias de *prompting* em cadeia de raciocínio melhoram desempenho em problemas complexos. A pesquisa orienta seleção de LLMs e *prompts* para gerar código mais eficiente.

## 2. Fichamento Bibliográfico

* *Large language models* (*LLMs*) (Modelos de Linguagem de Grande Escala) geram código a partir de descrições em linguagem natural, medido em *Pass@k* para correção funcional (p. 1).
* *Runtime* (Tempo de Execução) é avaliado em *gem5 CPU simulator* para HumanEval e MBPP e por métricas de porcentagem de usuários superados em LeetCode, repetido múltiplas vezes para reduzir ruído (pp. 2–3).
* *Pass@10* (Probabilidade de ao menos uma das 10 amostras passar) quantifica a correção funcional dos LLMs em benchmarks de síntese de programas (p. 5).
* *Prompting* (Formulação de Perguntas) em três estilos—direto, otimização simples, e otimização guiada por análise de estratégia—melhora eficiência de código, especialmente em problemas de complexidade média no LeetCode (pp. 4–5).
* Modelos avaliados incluem GPT-4, GPT-3.5, *Phi-2*, *Code Llama* (7B, 13B, 34B), *WizardCoder* (7B, 13B, 34B) e *DeepSeek Coder* (33B *base* e *instruct*) (p. 2).

## 3. Fichamento de Citações

* _"Efficient code can lead to higher performance and execution efficiency of programs and software completed by LLM-assisted programming."_
* _"We take the longest of these runtimes ... as the final runtime of the LLM on the problem."_
* _"The ability to generate correct code is not positively correlated with the ability to generate efficient code."_
* _"Larger number of parameters does not promise higher performance ... models of varying sizes share similar performance due to their reliance on the same training data."_
* _"Step-by-step prompting could make LLM to generate more efficient code, especially on complex problems."_
* _"HumanEval and MBPP problems have lower average difficulty ... resulting in a constrained optimization space and similar performance across prompt methods."_
* _"Comprehensive test cases on LeetCode can make the runtime benefits of code with real less complexity more significant."_