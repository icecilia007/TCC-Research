# Semantic Textual Similarity Analysis of Clinical Text in the Era of LLM

Feng, Yeli. "Semantic Textual Similarity Analysis of Clinical Text in the Era of LLM," in 2024 IEEE Conference on Artificial Intelligence (CAI), Singapore, 2024, pp. 1281-1286. doi: [10.1109/CAI59869.2024.00227](https://doi.org/10.1109/CAI59869.2024.00227)

## 1. Fichamento de Conteúdo

Neste trabalho, investiga-se o uso de *large language models* (LLMs) para análise de similaridade textual semântica (STS) em textos clínicos multilíngues. O problema central consiste em maximizar a eficácia e a eficiência da análise de STS em ambientes clínicos, avaliando-se se modelos gerais de última geração dispõem de desempenho comparável ao de LLMs especializados em domínio biomédico. Propõe-se o método *multi-layer transformer embeddings* (MLTE), que agrega *embeddings* de todas as camadas de um transformador em um vetor de características semânticas mais rico. Adota-se abordagem unificada de idiomas por meio de tradução automática de textos não ingleses para o inglês, e implementa-se arquitetura *bi-encoder* para viabilizar aplicações em larga escala com requisitos de baixa latência. A avaliação compara modelos pré-treinados, incluindo versões biomédicas de *Bidirectional Encoder Representations from Transformers* (BERT) e instâncias de *Text-to-Text Transfer Transformer* (T5) de domínio geral, demonstrando que o *Sentence-T5-large* apresenta desempenho superior aos modelos BERT especializados quando utilizados como *bi-encoders*. O MLTE foi testado em quatro conjuntos de dados clínicos multilíngues: BIOSSES (inglês), EBMSASS (inglês), JACSTS (japonês) e CHIP-STS (chinês). Os resultados revelam que o *Sentence-T5-large-ft-MLTE* alcança correlação de Pearson de 0,9248 no BIOSSES, 0,8879 no EBMSASS, 0,8652 no JACSTS e F1-score macro de 0,8527 no CHIP-STS. Comparativamente a trabalhos anteriores, o método proposto supera o estado da arte em dois dos quatro conjuntos de dados e mantém desempenho competitivo nos demais.

## 2. Fichamento Bibliográfico

* *Semantic textual similarity* (*STS*) (Similaridade Textual Semântica) é técnica essencial que prediz relacionamentos entre pares de textos curtos, sendo fundamental para recuperação de informação, categorização de texto e sistemas de pergunta-resposta em *NLP* clínico (página 1281).
* *Multi-layer transformer embeddings* (*MLTE*) (Embeddings de Transformer Multicamadas) extraem características de todas as camadas de blocos codificadores do *LLM*, fusionando-as em característica de entrada para análise semântica mais rica, inspirado no método *embeddings from language model* (*ELMo*) (páginas 1283-1284).
* *Large language models* (*LLMs*) (Modelos de Linguagem de Grande Escala) incluem *BERT*, *T5* e *GPT*, sendo que modelos *T5* de domínio geral demonstraram melhor desempenho que modelos *BERT* especializados em biomedicina quando usados como *bi-encoders* (páginas 1284-1285).
* *Bi-encoder* versus *cross-encoder* representam diferentes paradigmas arquiteturais, onde *bi-encoders* processam sentenças independentemente sendo mais adequados para aplicações em tempo real, enquanto *cross-encoders* concatenam pares de sentenças mas são computacionalmente intensivos (página 1282).
* A abordagem multilíngue unificada utiliza tradução automática para converter textos não ingleses em inglês, permitindo o uso de um único modelo especializado e simplificando o *deployment* em ambientes multilíngues (páginas 1283–1284).
* As métricas de avaliação incluem correlação de Pearson e Spearman para tarefas de regressão de similaridade, além de acurácia e F1-score macro para tarefas de classificação binária (página  1284).

## 3. Fichamento de Citações

* _"Semantic Textual Similarity (STS) analysis predicts the relationship between pairs of short texts. It is considered the most essential technique for various applications such as information retrieval, text categorization, question-answering systems."_
* _"Research in STS analysis has progressed significantly, thanks to the recent technology breakthrough in Large Language Models (LLM)."_
* _"Although cross-encoders often outperform bi-encoders in prediction accuracy, they are computationally intensive. They can be excessively slower at inference time, especially for large-scale prior knowledge retrieval."_
* _"Therefore, bi-encoders are more suitable for real-world applications when scaling and speed matter."_
* _"This paper experimentally shows that the recent advance in machine translation makes it feasible to take a language-unified approach to the STS task for the multilingual clinical text."_
* _"The semantic representation power of embeddings from BERT models fine-tuned with biomedical or clinical corpora don't naturally exhibit a performance advantage over embedding produced by more recent T5 Transformer trained for the general domain."_